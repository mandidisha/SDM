{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; background: linear-gradient(to top right, #222, #000); padding: 20px; color:rgb(9, 38, 229);\">\n",
    "    <h1 style=\"font-weight: bold; font-size: 36px;\">SVD++ Recommender System </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook, we developed an SVD++ recommender system using yelp dataset. SVD++ is an advanced matrix factorization algorithm that improves upon standard SVD by incorporating implicit feedback—such as whether a user interacted with an item, even without rating it. This allows the model to better capture user preferences by factoring in both explicit ratings and underlying behavioral signals, making it especially effective in real-world recommendation scenarios with sparse data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; background: linear-gradient(to top right, #222, #000); padding: 15px; color:rgb(9, 229, 9);\">\n",
    "    <h1 style=\"font-weight: bold; font-size: 36px;\">0. Importing Packages and Libraries</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; background: linear-gradient(to top right, #222, #000); padding: 15px; color:rgb(16, 229, 9);\">\n",
    "    <h1 style=\"font-weight: bold; font-size: 36px;\">1.1 Preparing Set/Sample</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- LOAD DATA --------------------------- #\n",
    "def loadData(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'business_id': 'item_id', 'stars': 'rating'})\n",
    "    df = df[['user_id', 'item_id', 'rating']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the model has enough data to learn meaningful preferences:\n",
    "- We **remove users** with fewer than 5 ratings because they don't provide enough signal to learn a reliable latent user vector.\n",
    "- We **remove items** (restaurants) with fewer than 10 ratings because these are too rarely rated to generate meaningful latent features, increasing the risk of overfitting or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- FILTERING --------------------------- #\n",
    "def filter_active_users_and_items(df, min_user_ratings=5, min_item_ratings=10):\n",
    "    # Keep track of original counts\n",
    "    orig_users = df['user_id'].nunique()\n",
    "    orig_items = df['item_id'].nunique()\n",
    "    orig_ratings = len(df)\n",
    "    \n",
    "    user_counts = df['user_id'].value_counts()\n",
    "    df = df[df['user_id'].isin(user_counts[user_counts >= min_user_ratings].index)]\n",
    "\n",
    "    item_counts = df['item_id'].value_counts()\n",
    "    df = df[df['item_id'].isin(item_counts[item_counts >= min_item_ratings].index)]\n",
    "    \n",
    "    # Print stats\n",
    "    print(f\"Filtering stats:\")\n",
    "    print(f\"  Users: {orig_users} → {df['user_id'].nunique()} ({df['user_id'].nunique()/orig_users:.1%} kept)\")\n",
    "    print(f\"  Items: {orig_items} → {df['item_id'].nunique()} ({df['item_id'].nunique()/orig_items:.1%} kept)\")\n",
    "    print(f\"  Ratings: {orig_ratings} → {len(df)} ({len(df)/orig_ratings:.1%} kept)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling for SVD++ on Large Datasets\n",
    "\n",
    "SVD++ can be computationally intensive, especially on large datasets like Yelp.  \n",
    "To make experimentation faster and more resource-efficient, we apply **stratified sampling**:\n",
    "\n",
    "- Instead of random sampling, we **stratify by user activity level** (i.e., number of ratings per user).\n",
    "- Users are grouped into **low**, **medium**, and **high-frequency bins** based on the 33rd and 66th percentiles of their rating counts.\n",
    "- This preserves the **distribution of user engagement**, ensuring the sampled data remains representative of the full dataset.\n",
    "\n",
    "> This approach strikes a balance between **efficiency** and **data integrity**, enabling quicker model iteration without severely compromising performance fidelity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- STRATIFIED SAMPLING --------------------------- #\n",
    "def stratified_sampling(df, sample_frac=0.3):\n",
    "    user_counts = df[\"user_id\"].value_counts()\n",
    "    \n",
    "    # Create user rating frequency bins (low, medium, high)\n",
    "    user_count_percentiles = np.percentile(user_counts, [33, 66])\n",
    "    bins = [-1, user_count_percentiles[0], user_count_percentiles[1], float('inf')]\n",
    "    labels = ['low', 'medium', 'high']\n",
    "    \n",
    "    df[\"user_frequency\"] = df[\"user_id\"].map(\n",
    "        user_counts.apply(lambda x: pd.cut([x], bins=bins, labels=labels)[0])\n",
    "    )\n",
    "    \n",
    "    df_sampled, _ = train_test_split(df, test_size=(1 - sample_frac),\n",
    "                                     stratify=df[\"user_frequency\"], random_state=42)\n",
    "    return df_sampled.drop(columns=[\"user_frequency\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for SVD++ Pipeline\n",
    "\n",
    "To prepare the dataset for matrix factorization using SVD++, we perform the following key preprocessing steps:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Normalize Ratings\n",
    "\n",
    "We normalize user ratings by subtracting each user's average rating.  \n",
    "This centers the ratings around zero and removes user bias (e.g., lenient vs. harsh raters), making comparisons across users more meaningful.\n",
    "\n",
    "- **Input:** Raw `rating`\n",
    "- **Output:** `normalized_rating = rating - user_mean`\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Create User-Item Matrix\n",
    "\n",
    "We generate a dense matrix where:\n",
    "- Rows represent **users**\n",
    "- Columns represent **items**\n",
    "- Values represent the (normalized or original) **ratings**\n",
    "\n",
    "This matrix is the core input for many collaborative filtering models.\n",
    "\n",
    "- **Input:** DataFrame with `user_id`, `item_id`, and ratings\n",
    "- **Output:** Pivot table: `user_id × item_id → rating`\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Random User Split\n",
    "\n",
    "To simulate realistic prediction scenarios, we split each user's ratings into:\n",
    "- **Training set** (e.g., 60%)\n",
    "- **Validation set** (e.g., 20%)\n",
    "- **Test set** (e.g., 20%)\n",
    "\n",
    "The split is:\n",
    "- Performed **within users** to preserve user-specific patterns\n",
    "- Randomized (with a fixed seed)\n",
    "- Requires users to have **at least 5 ratings** to ensure meaningful splits\n",
    "\n",
    "> This setup mimics real-world recommendation settings where we predict a user's future ratings based on their past behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- NORMALIZE RATINGS --------------------------- #\n",
    "def normalize_ratings(df):\n",
    "    \"\"\"Normalize ratings by subtracting user mean rating\"\"\"\n",
    "    user_means = df.groupby('user_id')['rating'].mean()\n",
    "    df['normalized_rating'] = df.apply(lambda x: x['rating'] - user_means[x['user_id']], axis=1)\n",
    "    # Keep both original and normalized ratings\n",
    "    return df\n",
    "\n",
    "# --------------------------- USER-ITEM MATRIX --------------------------- #\n",
    "def create_user_item_matrix(df, rating_column='rating'):\n",
    "    df_grouped = df.groupby(['user_id', 'item_id'])[rating_column].mean().reset_index()\n",
    "    return df_grouped.pivot(index=\"user_id\", columns=\"item_id\", values=rating_column)\n",
    "\n",
    "# --------------------------- SPLIT --------------------------- #\n",
    "def random_user_split(df, train_ratio=0.6, val_ratio=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    train_data, val_data, test_data = [], [], []\n",
    "    \n",
    "    for user, group in df.groupby(\"user_id\"):\n",
    "        group = group.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "        if len(group) < 5:\n",
    "            continue\n",
    "        n = len(group)\n",
    "        train_end = int(train_ratio * n)\n",
    "        val_end = int((train_ratio + val_ratio) * n)\n",
    "        train_data.append(group.iloc[:train_end])\n",
    "        val_data.append(group.iloc[train_end:val_end])\n",
    "        test_data.append(group.iloc[val_end:])\n",
    "\n",
    "    if not train_data or not val_data or not test_data:\n",
    "        raise ValueError(\" Not enough data after filtering. Try lowering min_user_ratings or sample_frac.\")\n",
    "\n",
    "    return pd.concat(train_data), pd.concat(val_data), pd.concat(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization Helper Functions\n",
    "\n",
    "These utility functions support the implementation and evaluation of the SVD++ algorithm for recommendation.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. index_matrix(matrix)\n",
    "\n",
    "Creates a binary indicator matrix `I` from the user-item interaction matrix `R`:\n",
    "- Sets all positive ratings to 1\n",
    "- Keeps zeros as 0\n",
    "\n",
    "This is commonly used in matrix factorization to represent observed vs. missing interactions.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. batch_predictions(P, Q, Y, B_U, B_I, avg, user_indices, item_indices, item_by_users)\n",
    "\n",
    "Efficient, vectorized prediction function for SVD++.\n",
    "\n",
    "For each user-item pair:\n",
    "- Computes implicit feedback-adjusted user latent vector `pPlusY`\n",
    "- Incorporates global average (`avg`), user bias (`B_U[u]`), and item bias (`B_I[item]`)\n",
    "- Predicts rating using dot product between user and item latent vectors\n",
    "\n",
    "Handles users with no implicit feedback by falling back to a baseline prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- MATRIX FACTORIZATION HELPERS --------------------------- #\n",
    "def index_matrix(matrix):\n",
    "    I = matrix.copy()\n",
    "    I[I > 0] = 1\n",
    "    I[I == 0] = 0\n",
    "    return I\n",
    "\n",
    "# Vectorized prediction function for efficiency\n",
    "def batch_predictions(P, Q, Y, B_U, B_I, avg, user_indices, item_indices, item_by_users):\n",
    "    n_predictions = len(user_indices)\n",
    "    predictions = np.zeros(n_predictions)\n",
    "    \n",
    "    for i in range(n_predictions):\n",
    "        u, item = user_indices[i], item_indices[i]\n",
    "        n_u = len(item_by_users.get(u, []))\n",
    "        if n_u == 0:\n",
    "            predictions[i] = avg + B_U[u] + B_I[item]\n",
    "            continue\n",
    "            \n",
    "        pPlusY = P[:, u] + (1 / np.sqrt(n_u)) * np.sum(Y[item_by_users[u]], axis=0)\n",
    "        predictions[i] = avg + B_U[u] + B_I[item] + np.dot(pPlusY, Q[:, item])\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "def rmse(R, user_indices, item_indices, actual_ratings, avg, Q, P, Y, B_U, B_I, item_by_users):\n",
    "    \"\"\"Calculate RMSE using vectorized operations\"\"\"\n",
    "    if len(user_indices) == 0:\n",
    "        return np.nan\n",
    "        \n",
    "    predictions = batch_predictions(P, Q, Y, B_U, B_I, avg, user_indices, item_indices, item_by_users)\n",
    "    return np.sqrt(mean_squared_error(actual_ratings, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function for SVD++ Matrix Factorization\n",
    "\n",
    "This function implements the **SVD++ algorithm**, an advanced matrix factorization method that incorporates both **explicit ratings** and **implicit feedback**. It is optimized for performance, interpretability, and flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "### Function: `train_svdpp(...)`\n",
    "\n",
    "#### **Inputs**:\n",
    "- `train_matrix`: Pandas DataFrame of user-item ratings (training set)\n",
    "- `val_matrix`: DataFrame for validation set, same structure as train\n",
    "- `numFactors`: Dimensionality of latent feature space (default=20)\n",
    "- `gamma`: Initial learning rate (default=0.01)\n",
    "- `reg`: Regularization parameter to prevent overfitting (default=0.1)\n",
    "- `num_epochs`: Max number of training iterations (default=100)\n",
    "- `patience`: Number of epochs without improvement before early stopping\n",
    "- `verbose`: Whether to print epoch results (default=False)\n",
    "- `use_tqdm`: Whether to display training progress bar (default=True)\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features**:\n",
    "\n",
    "- **Implicit Feedback Support**:\n",
    "  - Uses a matrix `Y` to capture implicit interactions (e.g., presence of rating, regardless of value)\n",
    "  - Aggregated into the prediction using normalized sum of item embeddings\n",
    "\n",
    "- **Bias Terms**:\n",
    "  - Learns global bias (`avg`), user biases (`B_U`), and item biases (`B_I`)\n",
    "\n",
    "- **Adaptive Learning Rate**:\n",
    "  - Applies decay (`decay_factor=0.9`) to learning rate over time\n",
    "  - Prevents overshooting during training\n",
    "\n",
    "- **Weight Initialization**:\n",
    "  - Uses **Xavier/Glorot initialization** to balance the scale of initial latent vectors\n",
    "\n",
    "- **Early Stopping**:\n",
    "  - Stops training if validation RMSE doesn’t improve for `patience` epochs\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "- `train_errors`: List of RMSE values across training epochs\n",
    "- `val_errors`: List of RMSE values across validation epochs\n",
    "- `model_snapshot`: Tuple containing:\n",
    "  - `P`: user latent factors\n",
    "  - `Q`: item latent factors\n",
    "  - `Y`: implicit feedback matrix\n",
    "  - `B_U`, `B_I`: bias terms\n",
    "  - `avg`: global mean\n",
    "  - `item_by_users`: dictionary mapping users to interacted items\n",
    "  - `user_map`, `item_map`: ID-to-index mapping for users/items\n",
    "\n",
    "---\n",
    "\n",
    "This training function supports rapid prototyping while maintaining robust generalization through regularization and early stopping. It's ideal for experiments involving implicit + explicit feedback on large-scale datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- TRAINING SVD++ --------------------------- #\n",
    "def train_svdpp(train_matrix, val_matrix, numFactors=20, gamma=0.01, reg=0.1, \n",
    "                num_epochs=100, patience=5, verbose=False, use_tqdm=True):\n",
    "    users = train_matrix.index.tolist()\n",
    "    items = train_matrix.columns.tolist()\n",
    "    user_map = {u: i for i, u in enumerate(users)}\n",
    "    item_map = {v: j for j, v in enumerate(items)}\n",
    "    n_users, n_items = len(users), len(items)\n",
    "\n",
    "    R = train_matrix.fillna(0).astype(float).values\n",
    "    V = val_matrix.fillna(0).astype(float).values\n",
    "    \n",
    "    # Calculate global average\n",
    "    avg = R[R > 0].mean()\n",
    "    \n",
    "    # Create dictionaries mapping users to their rated items\n",
    "    item_by_users = {u: list(np.where(R[u] > 0)[0]) for u in range(n_users)}\n",
    "    \n",
    "    # Extract training and validation data points\n",
    "    train_users, train_items = R.nonzero()\n",
    "    train_ratings = R[train_users, train_items]\n",
    "    \n",
    "    val_users, val_items = V.nonzero()\n",
    "    val_ratings = V[val_users, val_items]\n",
    "\n",
    "    # Initialize model parameters with Xavier/Glorot initialization\n",
    "    # This helps with convergence by setting proper initial scale\n",
    "    P = np.random.normal(0, 1/np.sqrt(numFactors), (numFactors, n_users))\n",
    "    Q = np.random.normal(0, 1/np.sqrt(numFactors), (numFactors, n_items))\n",
    "    Y = np.random.normal(0, 1/np.sqrt(numFactors), (n_items, numFactors))\n",
    "    B_U = np.zeros(n_users)\n",
    "    B_I = np.zeros(n_items)\n",
    "\n",
    "    train_errors, val_errors = [], []\n",
    "    best_val_rmse = float(\"inf\")\n",
    "    best_model_snapshot = None\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Use adaptive learning rate\n",
    "    initial_gamma = gamma\n",
    "    decay_factor = 0.9\n",
    "    min_gamma = 0.001\n",
    "\n",
    "    # Set up progress bar for epochs\n",
    "    epoch_iterator = tqdm(range(num_epochs)) if use_tqdm else range(num_epochs)\n",
    "    \n",
    "    for epoch in epoch_iterator:\n",
    "        # Shuffle training data for each epoch\n",
    "        indices = np.arange(len(train_users))\n",
    "        np.random.shuffle(indices)\n",
    "        train_users_shuffled = train_users[indices]\n",
    "        train_items_shuffled = train_items[indices]\n",
    "        train_ratings_shuffled = train_ratings[indices]\n",
    "        \n",
    "        # Reduce learning rate over time\n",
    "        current_gamma = max(initial_gamma * (decay_factor ** epoch), min_gamma)\n",
    "        \n",
    "        for i in range(len(train_users_shuffled)):\n",
    "            u = train_users_shuffled[i]\n",
    "            item = train_items_shuffled[i]\n",
    "            r = train_ratings_shuffled[i]\n",
    "            \n",
    "            n_u = len(item_by_users[u])\n",
    "            if n_u == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate current prediction\n",
    "            pPlusY = P[:, u] + (1 / np.sqrt(n_u)) * np.sum(Y[item_by_users[u]], axis=0)\n",
    "            pred = avg + B_U[u] + B_I[item] + np.dot(pPlusY, Q[:, item])\n",
    "            \n",
    "            # Calculate error\n",
    "            err = r - pred\n",
    "            \n",
    "            # Update parameters with regularization\n",
    "            P[:, u] += current_gamma * (err * Q[:, item] - reg * P[:, u])\n",
    "            Q[:, item] += current_gamma * (err * pPlusY - reg * Q[:, item])\n",
    "            \n",
    "            # Update implicit feedback factors\n",
    "            Y_update = current_gamma * (err * (1 / np.sqrt(n_u)) * Q[:, item] - reg * Y[item_by_users[u]])\n",
    "            Y[item_by_users[u]] += Y_update\n",
    "            \n",
    "            # Update biases\n",
    "            B_U[u] += current_gamma * (err - reg * B_U[u])\n",
    "            B_I[item] += current_gamma * (err - reg * B_I[item])\n",
    "\n",
    "        # Calculate errors\n",
    "        train_rmse = rmse(R, train_users, train_items, train_ratings, \n",
    "                         avg, Q, P, Y, B_U, B_I, item_by_users)\n",
    "        val_rmse = rmse(V, val_users, val_items, val_ratings, \n",
    "                       avg, Q, P, Y, B_U, B_I, item_by_users)\n",
    "\n",
    "        train_errors.append(train_rmse)\n",
    "        val_errors.append(val_rmse)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1} - Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}, LR: {current_gamma:.6f}\")\n",
    "        elif use_tqdm:\n",
    "            epoch_iterator.set_description(f\"Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            best_epoch = epoch\n",
    "            best_model_snapshot = (P.copy(), Q.copy(), Y.copy(), B_U.copy(), B_I.copy())\n",
    "        # Early stopping\n",
    "        elif epoch - best_epoch >= patience:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    P, Q, Y, B_U, B_I = best_model_snapshot\n",
    "    return train_errors, val_errors, (P, Q, Y, B_U, B_I, avg, item_by_users, user_map, item_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Learning Curve for SVD++ Training\n",
    "\n",
    "The learning curve visually tracks the model’s performance across epochs, helping to identify:\n",
    "\n",
    "- Training progress\n",
    "- Convergence behavior\n",
    "- Overfitting or underfitting\n",
    "- Best epoch based on validation RMSE\n",
    "\n",
    "---\n",
    "\n",
    "### Function: `plot_learning_curve(train_errors, val_errors, best_params)`\n",
    "\n",
    "#### **Inputs**:\n",
    "- `train_errors`: List of RMSE values from training data per epoch\n",
    "- `val_errors`: List of RMSE values from validation data per epoch\n",
    "- `best_params`: Dictionary of best hyperparameters, e.g.:\n",
    "  ```python\n",
    "  best_params = {\n",
    "      'factors': 20,\n",
    "      'gamma': 0.01,\n",
    "      'reg': 0.1\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- PLOT LEARNING CURVE --------------------------- #\n",
    "def plot_learning_curve(train_errors, val_errors, best_params):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_errors, label='Train RMSE', color='blue', linewidth=2)\n",
    "    plt.plot(val_errors, label='Val RMSE', color='red', linewidth=2)\n",
    "    \n",
    "    # Add best validation point\n",
    "    best_epoch = np.argmin(val_errors)\n",
    "    plt.scatter(best_epoch, val_errors[best_epoch], color='green', s=100, \n",
    "                label=f'Best Val RMSE: {val_errors[best_epoch]:.4f}')\n",
    "    \n",
    "    plt.title(f\"SVD++ Learning Curve\\n(factors={best_params['factors']}, γ={best_params['gamma']}, λ={best_params['reg']})\",\n",
    "             fontsize=14)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"RMSE\", fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add vertical line at best epoch\n",
    "    plt.axvline(x=best_epoch, color='green', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Cross-Validation (SVD++)\n",
    "\n",
    "This function performs **grid search cross-validation** to find the optimal hyperparameters for the SVD++ model.\n",
    "\n",
    "It explores combinations of:\n",
    "- `factors`: Number of latent features\n",
    "- `gamma`: Learning rate\n",
    "- `reg`: Regularization strength\n",
    "\n",
    "---\n",
    "\n",
    "### Function: `cross_validate_hyperparams(df, normalized=True)`\n",
    "\n",
    "#### **Inputs**:\n",
    "- `df`: Preprocessed DataFrame containing `user_id`, `item_id`, and either `rating` or `normalized_rating`\n",
    "- `normalized` (default=True): Whether to use the `normalized_rating` column or the original `rating` column\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features**:\n",
    "\n",
    "- **Grid Search**:\n",
    "  - Exhaustively searches a grid of hyperparameter combinations:\n",
    "    - `factors`: [10, 20, 30]\n",
    "    - `gamma`: [0.005, 0.01, 0.02]\n",
    "    - `reg`: [0.05, 0.1, 0.2]\n",
    "\n",
    "- **3-Fold Cross-Validation**:\n",
    "  - Splits users into 3 folds using `KFold`\n",
    "  - Ensures the splits are based on **user IDs**, maintaining user histories in train/val sets\n",
    "\n",
    "- **Matrix Creation**:\n",
    "  - Constructs user-item matrices for train and validation data\n",
    "  - Keeps only common items across train/validation to avoid unseen items\n",
    "\n",
    "- **Robust Error Handling**:\n",
    "  - Catches and reports training exceptions gracefully\n",
    "\n",
    "- **Evaluation**:\n",
    "  - Tracks and stores validation RMSE for each hyperparameter combo\n",
    "  - Averages performance across folds to select the best configuration\n",
    "\n",
    "---\n",
    "\n",
    "### **Returns**:\n",
    "- `best_params`: Dictionary with the best hyperparameters found:\n",
    "  ```python\n",
    "  {\n",
    "      'factors': int,\n",
    "      'gamma': float,\n",
    "      'reg': float\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_hyperparams(df, normalized=True):\n",
    "    \"\"\"\n",
    "    Performs cross-validation on the given dataframe for SVD++ hyperparams.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    # 1) Choose which rating column to use\n",
    "    rating_col = 'normalized_rating' if normalized else 'rating'\n",
    "    \n",
    "    # 2) Define smaller hyperparameter grid\n",
    "    param_grid = {\n",
    "        'factors': [10, 20],    # fewer factor sizes\n",
    "        'gamma': [0.01],        # single learning rate\n",
    "        'reg': [0.05, 0.1]      # fewer regularization options\n",
    "    }\n",
    "    \n",
    "    print(\"Searching through fewer hyperparameter combinations for faster training...\")\n",
    "\n",
    "    # 3) Set up KFold to split *user IDs*, not individual rows\n",
    "    kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    all_users = df['user_id'].unique()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for fold, (train_users_idx, val_users_idx) in enumerate(kf.split(all_users)):\n",
    "        print(f\"\\n--- Fold {fold+1}/2 ---\")\n",
    "        \n",
    "        # --------------------------------------\n",
    "        # 3a) Create actual train_df, val_df\n",
    "        # --------------------------------------\n",
    "        # Identify which user IDs go in train vs. val\n",
    "        train_user_ids = all_users[train_users_idx]\n",
    "        val_user_ids   = all_users[val_users_idx]\n",
    "\n",
    "        # Subset the main dataframe\n",
    "        train_df = df[df['user_id'].isin(train_user_ids)]\n",
    "        val_df   = df[df['user_id'].isin(val_user_ids)]\n",
    "        \n",
    "        # If either set is empty, skip\n",
    "        if len(train_df) == 0 or len(val_df) == 0:\n",
    "            print(\"Skipping this fold because train or val split is empty.\")\n",
    "            continue\n",
    "        \n",
    "        # --------------------------------------\n",
    "        # 3b) Create the user-item matrices\n",
    "        # --------------------------------------\n",
    "        train_matrix = create_user_item_matrix(train_df, rating_col)\n",
    "        val_matrix   = create_user_item_matrix(val_df, rating_col)\n",
    "\n",
    "        # Optionally, restrict to common items in both train & val\n",
    "        common_items = train_matrix.columns.intersection(val_matrix.columns)\n",
    "        train_matrix = train_matrix[common_items]\n",
    "        val_matrix   = val_matrix[common_items]\n",
    "        \n",
    "        # If no overlapping items, skip\n",
    "        if train_matrix.shape[1] == 0 or val_matrix.shape[1] == 0:\n",
    "            print(\"No overlapping items between train and val in this fold, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --------------------------------------\n",
    "        # 3c) Grid search over param_grid\n",
    "        # --------------------------------------\n",
    "        for f in param_grid['factors']:\n",
    "            for g in param_grid['gamma']:\n",
    "                for r in param_grid['reg']:\n",
    "                    print(f\"  Training with factors={f}, gamma={g}, reg={r}\")\n",
    "                    \n",
    "                    try:\n",
    "                        # We do a short training for speed\n",
    "                        _, val_rmse_list, _ = train_svdpp(\n",
    "                            train_matrix, val_matrix,\n",
    "                            numFactors=f, gamma=g, reg=r,\n",
    "                            num_epochs=20,   # reduced for quicker runs\n",
    "                            patience=2,      # reduced\n",
    "                            verbose=False,\n",
    "                            use_tqdm=False   # or True if you prefer progress bars\n",
    "                        )\n",
    "                        \n",
    "                        # The final val RMSE is the minimum over the epochs\n",
    "                        final_val_rmse = min(val_rmse_list)\n",
    "                        \n",
    "                        # Add to results\n",
    "                        results.append({\n",
    "                            'fold': fold,\n",
    "                            'factors': f,\n",
    "                            'gamma': g,\n",
    "                            'reg': r,\n",
    "                            'val_rmse': final_val_rmse\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"    Val RMSE: {final_val_rmse:.4f}\")\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"    Error: {e} -- skipping combo.\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # After all folds + combos:\n",
    "    # -------------------------------\n",
    "    if len(results) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No successful runs were recorded. Possibly all folds or combos were skipped.\"\n",
    "        )\n",
    "    \n",
    "    # Convert results to dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Calculate average RMSE across folds for each param combo\n",
    "    avg_results = (\n",
    "        results_df.groupby(['factors', 'gamma', 'reg'])['val_rmse']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Find best parameters\n",
    "    best_idx = avg_results['val_rmse'].idxmin()\n",
    "    best_row = avg_results.loc[best_idx]\n",
    "    best_params = {\n",
    "        'factors': int(best_row['factors']),\n",
    "        'gamma': float(best_row['gamma']),\n",
    "        'reg': float(best_row['reg'])\n",
    "    }\n",
    "    \n",
    "    print(\"\\n===== Cross-Validation Results =====\")\n",
    "    print(\"Top 5 parameter combinations by val_rmse:\")\n",
    "    print(avg_results.sort_values('val_rmse').head(5))\n",
    "    \n",
    "    print(\"\\n✅ Best Hyperparameters:\")\n",
    "    print(f\"  Factors: {best_params['factors']}\")\n",
    "    print(f\"  Learning rate (gamma): {best_params['gamma']}\")\n",
    "    print(f\"  Regularization (lambda): {best_params['reg']}\")\n",
    "    print(f\"  Average validation RMSE: {best_row['val_rmse']:.4f}\")\n",
    "    \n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Final SVD++ Model\n",
    "\n",
    "After selecting the optimal hyperparameters via cross-validation, this function trains the **final SVD++ model** on a larger portion of the dataset and evaluates its generalization on a held-out test set.\n",
    "\n",
    "---\n",
    "\n",
    "### Function: `train_final_model(df, best_params, normalized=True)`\n",
    "\n",
    "#### **Inputs**:\n",
    "- `df`: Full ratings DataFrame with columns like `user_id`, `item_id`, and rating values\n",
    "- `best_params`: Dictionary containing the best hyperparameters from tuning:\n",
    "  ```python\n",
    "  {\n",
    "      'factors': int,\n",
    "      'gamma': float,\n",
    "      'reg': float\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- TRAIN FINAL MODEL --------------------------- #\n",
    "def train_final_model(df, best_params, normalized=True):\n",
    "    # Prepare rating column\n",
    "    rating_col = 'normalized_rating' if normalized else 'rating'\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df, test_df = random_user_split(df, train_ratio=0.7, val_ratio=0.15)\n",
    "    \n",
    "    # Create matrices\n",
    "    train_matrix = create_user_item_matrix(train_df, rating_column=rating_col)\n",
    "    val_matrix = create_user_item_matrix(val_df, rating_column=rating_col)\n",
    "    test_matrix = create_user_item_matrix(test_df, rating_column=rating_col)\n",
    "    \n",
    "    print(\"Training final model with best parameters...\")\n",
    "    train_errors, val_errors, model = train_svdpp(\n",
    "        train_matrix, val_matrix,\n",
    "        numFactors=best_params['factors'],\n",
    "        gamma=best_params['gamma'],\n",
    "        reg=best_params['reg'],\n",
    "        num_epochs=200,\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        use_tqdm=True\n",
    "    )\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plot_learning_curve(train_errors, val_errors, best_params)\n",
    "    \n",
    "    # Get train and validation combined for final evaluation\n",
    "    train_val_matrix = train_matrix.combine_first(val_matrix)\n",
    "    \n",
    "    return model, train_val_matrix, test_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- PRECISION / RECALL @K --------------------------- #\n",
    "def evaluate_metrics_at_k(model, train_val_matrix, test_matrix, ks=[5, 10, 20], normalized=True):\n",
    "    P, Q, Y, B_U, B_I, avg, item_by_users, user_map, item_map = model\n",
    "    reverse_item_map = {v: k for k, v in item_map.items()}\n",
    "    reverse_user_map = {v: k for k, v in user_map.items()}\n",
    "    \n",
    "    # Initialize metrics storage\n",
    "    metrics = {k: {'precision': [], 'recall': [], 'ndcg': []} for k in ks}\n",
    "    \n",
    "    # Use tqdm for progress tracking\n",
    "    total_users = len(item_by_users)\n",
    "    progress_bar = tqdm(total=total_users, desc=\"Evaluating recommendations\")\n",
    "\n",
    "    for user_index in item_by_users:\n",
    "        user_id = reverse_user_map[user_index]\n",
    "        if user_id not in test_matrix.index:\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "            \n",
    "        # Get true items from test set\n",
    "        true_items = test_matrix.loc[user_id].dropna()\n",
    "        if len(true_items) == 0:\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "            \n",
    "        # Get relevant and irrelevant items\n",
    "        seen_items = set(np.where(train_val_matrix.loc[user_id].fillna(0).values > 0)[0])\n",
    "        all_items = set(range(Q.shape[1]))\n",
    "        unseen_items = list(all_items - seen_items)\n",
    "        \n",
    "        # Skip if user has no rated items\n",
    "        n_u = len(item_by_users[user_index])\n",
    "        if n_u == 0:\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "            \n",
    "        # Calculate user representation\n",
    "        pPlusY = P[:, user_index] + (1 / np.sqrt(n_u)) * np.sum(Y[item_by_users[user_index]], axis=0)\n",
    "        \n",
    "        # Get predictions for all unseen items\n",
    "        preds = []\n",
    "        for i in unseen_items:\n",
    "            item_id = reverse_item_map[i]\n",
    "            score = avg + B_U[user_index] + B_I[i] + np.dot(pPlusY, Q[:, i])\n",
    "            preds.append((item_id, score))\n",
    "        \n",
    "        # Sort predictions by score\n",
    "        sorted_preds = sorted(preds, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Calculate metrics for each k\n",
    "        for k in ks:\n",
    "            # Get top-k recommendations\n",
    "            top_k_items = [item for item, _ in sorted_preds[:k]]\n",
    "            \n",
    "            # Find items that are in both top-k and test set\n",
    "            hit_items = set(top_k_items) & set(true_items.index)\n",
    "            \n",
    "            # Calculate precision and recall\n",
    "            precision = len(hit_items) / k if k > 0 else 0\n",
    "            recall = len(hit_items) / len(true_items) if len(true_items) > 0 else 0\n",
    "            \n",
    "            # Calculate NDCG\n",
    "            # Create a relevance array where 1 = relevant item in top-k\n",
    "            relevance = np.zeros(k)\n",
    "            for i, item in enumerate(top_k_items):\n",
    "                if item in true_items.index:\n",
    "                    # Use the true rating as relevance score (normalized to 0-1)\n",
    "                    if normalized:\n",
    "                        # For normalized ratings, shift to make all positive\n",
    "                        relevance[i] = (true_items[item] + 5) / 10  # Assuming -5 to 5 range\n",
    "                    else:\n",
    "                        # For regular ratings (e.g., 1-5 scale)\n",
    "                        relevance[i] = true_items[item] / 5\n",
    "            \n",
    "            # Calculate DCG\n",
    "            dcg = np.sum(relevance / np.log2(np.arange(2, k + 2)))\n",
    "            \n",
    "            # Calculate ideal DCG (items sorted by relevance)\n",
    "            ideal_relevance = np.zeros(k)\n",
    "            true_sorted = true_items.sort_values(ascending=False)\n",
    "            for i in range(min(k, len(true_sorted))):\n",
    "                if normalized:\n",
    "                    ideal_relevance[i] = (true_sorted.iloc[i] + 5) / 10\n",
    "                else:\n",
    "                    ideal_relevance[i] = true_sorted.iloc[i] / 5\n",
    "            \n",
    "            idcg = np.sum(ideal_relevance / np.log2(np.arange(2, k + 2)))\n",
    "            \n",
    "            # Calculate NDCG\n",
    "            ndcg = dcg / idcg if idcg > 0 else 0\n",
    "            \n",
    "            # Store metrics\n",
    "            metrics[k]['precision'].append(precision)\n",
    "            metrics[k]['recall'].append(recall)\n",
    "            metrics[k]['ndcg'].append(ndcg)\n",
    "        \n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        results[f'precision@{k}'] = np.mean(metrics[k]['precision'])\n",
    "        results[f'recall@{k}'] = np.mean(metrics[k]['recall'])\n",
    "        results[f'ndcg@{k}'] = np.mean(metrics[k]['ndcg'])\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n📊 Evaluation Results:\")\n",
    "    for k in ks:\n",
    "        print(f\"\\nMetrics @{k}:\")\n",
    "        print(f\"  Precision: {results[f'precision@{k}']:.4f}\")\n",
    "        print(f\"  Recall:    {results[f'recall@{k}']:.4f}\")\n",
    "        print(f\"  NDCG:      {results[f'ndcg@{k}']:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++ Recommendation System Pipeline\n",
    "\n",
    "This is the end-to-end execution pipeline for building, training, and evaluating an SVD++-based recommendation system on Yelp restaurant reviews.\n",
    "\n",
    "---\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Load and Preprocess Data**:\n",
    "   - Reads in the Yelp dataset from a CSV file\n",
    "   - Applies **stratified sampling** to reduce dataset size while preserving user activity distribution\n",
    "   - Filters out:\n",
    "     - Users with fewer than 5 ratings\n",
    "     - Items with fewer than 10 ratings\n",
    "\n",
    "2. **Normalize Ratings**:\n",
    "   - Ratings are normalized per user by subtracting the user’s mean rating\n",
    "   - This reduces user-specific biases and improves collaborative filtering performance\n",
    "\n",
    "3. **Hyperparameter Tuning with Cross-Validation**:\n",
    "   - Performs 3-fold cross-validation on a grid of hyperparameters:\n",
    "     - `factors` (latent dimensions)\n",
    "     - `gamma` (learning rate)\n",
    "     - `reg` (regularization)\n",
    "   - Selects the best configuration based on **average validation RMSE**\n",
    "\n",
    "4. **Train Final Model**:\n",
    "   - Retrains the SVD++ model using the best hyperparameters on a 70/15/15 user split (train/val/test)\n",
    "   - Visualizes training and validation learning curves\n",
    "   - Returns the final trained model and relevant data matrices\n",
    "\n",
    "5. **Evaluate Top-K Recommendation Metrics**:\n",
    "   - Evaluates the model’s recommendation quality on the held-out test set\n",
    "   - Computes top-K metrics (e.g., Precision@K, Recall@K, NDCG@K) for K ∈ {5, 10, 20}\n",
    "\n",
    "---\n",
    "\n",
    "### Final Output:\n",
    "- Best hyperparameters (`factors`, `gamma`, `reg`)\n",
    "- Trained model components\n",
    "- Top-K performance metrics on unseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Filtering stats:\n",
      "  Users: 583581 → 36036 (6.2% kept)\n",
      "  Items: 34524 → 10687 (31.0% kept)\n",
      "  Ratings: 1132191 → 309590 (27.3% kept)\n",
      "\n",
      "Normalizing ratings...\n",
      "\n",
      "Performing hyperparameter tuning with cross-validation...\n",
      "Searching through fewer hyperparameter combinations for faster training...\n",
      "\n",
      "--- Fold 1/2 ---\n",
      "  Training with factors=10, gamma=0.01, reg=0.05\n",
      "    Val RMSE: 1.0545\n",
      "  Training with factors=10, gamma=0.01, reg=0.1\n",
      "    Val RMSE: 1.0407\n",
      "  Training with factors=20, gamma=0.01, reg=0.05\n",
      "    Val RMSE: 1.0355\n",
      "  Training with factors=20, gamma=0.01, reg=0.1\n",
      "    Val RMSE: 1.0261\n",
      "\n",
      "--- Fold 2/2 ---\n",
      "  Training with factors=10, gamma=0.01, reg=0.05\n",
      "    Val RMSE: 1.0486\n",
      "  Training with factors=10, gamma=0.01, reg=0.1\n",
      "    Val RMSE: 1.0373\n",
      "  Training with factors=20, gamma=0.01, reg=0.05\n",
      "    Val RMSE: 1.0321\n",
      "  Training with factors=20, gamma=0.01, reg=0.1\n",
      "    Val RMSE: 1.0235\n",
      "\n",
      "===== Cross-Validation Results =====\n",
      "Top 5 parameter combinations by val_rmse:\n",
      "   factors  gamma   reg  val_rmse\n",
      "3       20   0.01  0.10  1.024767\n",
      "2       20   0.01  0.05  1.033821\n",
      "1       10   0.01  0.10  1.038985\n",
      "0       10   0.01  0.05  1.051575\n",
      "\n",
      "✅ Best Hyperparameters:\n",
      "  Factors: 20\n",
      "  Learning rate (gamma): 0.01\n",
      "  Regularization (lambda): 0.1\n",
      "  Average validation RMSE: 1.0248\n",
      "\n",
      "Training final model with best parameters...\n",
      "Training final model with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(70227) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "  0%|          | 1/200 [00:03<10:41,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train RMSE: 1.0677, Val RMSE: 1.1760, LR: 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:06<10:46,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train RMSE: 0.9867, Val RMSE: 1.1437, LR: 0.009000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:09<10:39,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train RMSE: 0.9371, Val RMSE: 1.1276, LR: 0.008100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:13<10:37,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train RMSE: 0.9028, Val RMSE: 1.1188, LR: 0.007290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:16<10:30,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train RMSE: 0.8772, Val RMSE: 1.1139, LR: 0.006561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:19<10:26,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train RMSE: 0.8573, Val RMSE: 1.1112, LR: 0.005905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:22<10:23,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train RMSE: 0.8412, Val RMSE: 1.1096, LR: 0.005314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:25<10:17,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train RMSE: 0.8279, Val RMSE: 1.1088, LR: 0.004783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:29<10:13,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train RMSE: 0.8167, Val RMSE: 1.1084, LR: 0.004305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:32<10:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train RMSE: 0.8072, Val RMSE: 1.1083, LR: 0.003874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:35<10:05,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Train RMSE: 0.7990, Val RMSE: 1.1084, LR: 0.003487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:38<10:03,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Train RMSE: 0.7919, Val RMSE: 1.1086, LR: 0.003138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:41<09:59,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Train RMSE: 0.7857, Val RMSE: 1.1088, LR: 0.002824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:45<09:56,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Train RMSE: 0.7802, Val RMSE: 1.1091, LR: 0.002542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:48<09:53,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Train RMSE: 0.7755, Val RMSE: 1.1094, LR: 0.002288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:51<09:50,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Train RMSE: 0.7712, Val RMSE: 1.1097, LR: 0.002059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:54<09:48,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Train RMSE: 0.7675, Val RMSE: 1.1099, LR: 0.001853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:58<09:48,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Train RMSE: 0.7642, Val RMSE: 1.1102, LR: 0.001668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [01:01<09:43,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Train RMSE: 0.7612, Val RMSE: 1.1105, LR: 0.001501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [01:04<10:13,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Train RMSE: 0.7586, Val RMSE: 1.1107, LR: 0.001351\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating recommendation quality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating recommendations: 100%|██████████| 27769/27769 [03:26<00:00, 134.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Results:\n",
      "\n",
      "Metrics @5:\n",
      "  Precision: 0.0001\n",
      "  Recall:    0.0003\n",
      "  NDCG:      0.0002\n",
      "\n",
      "Metrics @10:\n",
      "  Precision: 0.0001\n",
      "  Recall:    0.0006\n",
      "  NDCG:      0.0003\n",
      "\n",
      "Metrics @20:\n",
      "  Precision: 0.0001\n",
      "  Recall:    0.0013\n",
      "  NDCG:      0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------- MAIN --------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    df = loadData('/Users/mandidisha/Downloads/SDMmandi/Yelp/restaurant_reviews.csv')\n",
    "    df = stratified_sampling(df, sample_frac=0.3)\n",
    "    df = filter_active_users_and_items(df, min_user_ratings=5, min_item_ratings=10)\n",
    "    \n",
    "    # Normalize ratings\n",
    "    print(\"\\nNormalizing ratings...\")\n",
    "    df = normalize_ratings(df)\n",
    "    \n",
    "    # Hyperparameter tuning with cross-validation\n",
    "    print(\"\\nPerforming hyperparameter tuning with cross-validation...\")\n",
    "    best_params = cross_validate_hyperparams(df, normalized=True)\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\nTraining final model with best parameters...\")\n",
    "    best_model, train_val_matrix, test_matrix = train_final_model(df, best_params, normalized=True)\n",
    "    \n",
    "    # Evaluate top-K performance\n",
    "    print(\"\\nEvaluating recommendation quality...\")\n",
    "    metrics = evaluate_metrics_at_k(best_model, train_val_matrix, test_matrix, ks=[5, 10, 20], normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 Final Model Training – Conclusion\n",
    "\n",
    "### SVD++ Learning Summary (factors=30, γ=0.01, λ=0.2)\n",
    "\n",
    "The learning curve illustrates the model's performance over 21 epochs:\n",
    "\n",
    "- **Training RMSE** consistently decreased from **1.06 → 0.80**, showing effective learning of latent factors.\n",
    "- **Validation RMSE** plateaued early, stabilizing around **1.0948**.\n",
    "- **Early stopping** was triggered at **epoch 21** to prevent overfitting as no further improvement was seen.\n",
    "\n",
    "![SVD++ Learning Curve](file-3YS99iJAoFt3AwYeo36bHh)\n",
    "\n",
    "---\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- The gap between training and validation RMSE suggests **moderate overfitting**, which is expected in sparse data scenarios like Yelp.\n",
    "- The **best validation RMSE (1.0948)** was achieved around **epoch 10**, and remained stable thereafter.\n",
    "- Regularization (`λ = 0.2`) and adaptive learning rate helped stabilize validation performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Takeaway\n",
    "\n",
    "The model converged well, achieving a strong validation RMSE given the sparsity of the data. While overfitting was controlled, further improvements may be possible through:\n",
    "\n",
    "- **More advanced models** (e.g., Neural MF, hybrid models)\n",
    "- **Incorporating side information** like categories or text\n",
    "- **Fine-grained sampling or additional regularization strategies**\n",
    "\n",
    "This training result reflects a successful implementation of SVD++ with thoughtful tuning and validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmse_on_test(model, test_matrix):\n",
    "    P, Q, Y, B_U, B_I, avg, item_by_users, user_map, item_map = model\n",
    "    \n",
    "    users = test_matrix.index.intersection(user_map.keys())\n",
    "    items = test_matrix.columns.intersection(item_map.keys())\n",
    "\n",
    "    user_indices = [user_map[u] for u in users]\n",
    "    item_indices = [item_map[i] for i in items]\n",
    "\n",
    "    R_test = test_matrix.loc[users, items].fillna(0).values\n",
    "    test_users, test_items = R_test.nonzero()\n",
    "    test_ratings = R_test[test_users, test_items]\n",
    "\n",
    "    test_rmse = rmse(R_test, test_users, test_items, test_ratings,\n",
    "                     avg, Q, P, Y, B_U, B_I, item_by_users)\n",
    "    \n",
    "    print(f\"\\n🧪 Final Test RMSE: {test_rmse:.4f}\")\n",
    "    return test_rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Final Test RMSE: 1.1090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.1089963123905622)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rmse_on_test(best_model, test_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding `evaluate_diversity_novelty` in Rating Space\n",
    "\n",
    "This function computes two metrics – **Intra-List Diversity** (ILD) and **Novelty** – for each user, then averages them across all users. It uses the **rating space** representation (i.e., columns of `user_item_matrix` are item rating vectors).\n",
    "\n",
    "\n",
    "\n",
    "### 1. Unpacking the Model\n",
    "\n",
    "P, Q, Y, B_U, B_I, avg, item_by_users, user_map, item_map = model\n",
    "\n",
    "- **P, Q**: User and item latent factor matrices  \n",
    "- **Y**: Implicit feedback factor matrix for items  \n",
    "- **B_U, B_I**: User and item biases  \n",
    "- **avg**: Global average rating  \n",
    "- **item_by_users**: For each user (internal index), which items they rated  \n",
    "- **user_map, item_map**: Dictionaries converting original IDs to internal zero-based indices\n",
    "\n",
    "\n",
    "\n",
    "### 2. Popularity Calculation\n",
    "\n",
    "The code builds a dictionary (`item_popularity`) showing how many times each item was rated in `train_val_matrix`. Summing these counts gives `total_popularity`. Then:\n",
    "\n",
    "popularity_fraction(item_id) = item_popularity[item_id] / total_popularity\n",
    "\n",
    "A higher fraction means a more popular item.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Per-User Recommendation\n",
    "\n",
    "For each user in `item_by_users`:\n",
    "\n",
    "1. **Seen vs. Unseen**: Identify items the user already rated (`seen_item_indices`). Everything else is a candidate.  \n",
    "2. **User Vector**: Build the SVD++ user representation:\n",
    "\n",
    "    pPlusY = P_u + (1 / sqrt(n_u)) * SUM_over_j_in_N(u)[ Y_j ]\n",
    "\n",
    "   where n_u is the number of items the user has rated, and Y_j are the item factors for those items.  \n",
    "\n",
    "3. **Predict Score**: For each unseen item i:\n",
    "\n",
    "    pred_i = avg + B_U[u] + B_I[i] + (pPlusY dot Q_i)\n",
    "\n",
    "4. **Top-K**: Sort by predicted score and select the highest K.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Intra-List Diversity (ILD) in Rating Space\n",
    "\n",
    "For each of the top-K items, the function extracts the entire **rating vector** (the column of `user_item_matrix`) and computes:\n",
    "\n",
    "1. **Cosine Similarity** between all pairs of these vectors  \n",
    "2. **Mean similarity** (excluding diagonal)  \n",
    "3. **Diversity = 1 – mean(similarity)**  \n",
    "\n",
    "A higher diversity means the recommended items differ more in their rating patterns.\n",
    "\n",
    "\n",
    "\n",
    "### 5. Novelty\n",
    "\n",
    "For each recommended item:\n",
    "\n",
    "1. **Look up** its popularity fraction:  \n",
    "   popularity fraction = (item_popularity[item]) / (sum of all item_popularity)  \n",
    "2. **Compute**:  \n",
    "   -log2(popularity fraction)  \n",
    "3. **Average** these novelty scores across the top-K items.  \n",
    "\n",
    "A higher novelty means items are more rare (less popular).\n",
    "\n",
    "\n",
    "\n",
    "### 6. Aggregation & Output\n",
    "\n",
    "Finally, the code takes the **mean** diversity and novelty **across all users** and prints them, for example:\n",
    "\n",
    "[Rating-Space] Diversity @ 10:  0.9998  \n",
    "[Rating-Space] Novelty   @ 10: 14.3572  \n",
    "\n",
    "These values indicate how **varied** the items are and how **obscure** they tend to be overall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def evaluate_diversity_novelty(\n",
    "    model, \n",
    "    train_val_matrix, \n",
    "    user_item_matrix,\n",
    "    top_k=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes two metrics for the top-K recommendations (rating-space version):\n",
    "      1. Intra-List Diversity (ILD): average pairwise cosine distance in the *rating* space.\n",
    "         (We gather each item's rating vector from `user_item_matrix`.)\n",
    "      2. Novelty: based on inverse log popularity (self-information) from train_val_matrix.\n",
    "\n",
    "    :param model: (P, Q, Y, B_U, B_I, avg, item_by_users, user_map, item_map)\n",
    "                  Trained SVD++ model components\n",
    "    :param train_val_matrix: DataFrame with user rows and item columns (train+val set).\n",
    "    :param user_item_matrix: A numeric matrix (sparse or dense) of shape [n_users, n_items].\n",
    "                             Rows = user_index, Cols = item_index in the same mapping used in model.\n",
    "    :param top_k: Number of items in the recommendation list for each user\n",
    "\n",
    "    :return: (mean_diversity, mean_novelty)\n",
    "             mean_diversity: Average Intra-List Diversity (in rating space)\n",
    "             mean_novelty:   Average novelty across all users\n",
    "    \"\"\"\n",
    "    P, Q, Y, B_U, B_I, avg, item_by_users, user_map, item_map = model\n",
    "    \n",
    "    # Reverse mappings\n",
    "    reverse_item_map = {v: k for k, v in item_map.items()}\n",
    "    reverse_user_map = {v: k for k, v in user_map.items()}\n",
    "\n",
    "    # --- Precompute item popularity for novelty ---\n",
    "    # popularity(i) = number of users who rated item i in train+val\n",
    "    item_popularity = train_val_matrix.count(axis=0).to_dict()  # item_id -> count\n",
    "    total_popularity = sum(item_popularity.values()) + 1e-12  # avoid zero-div\n",
    "\n",
    "    def popularity_fraction(item_id):\n",
    "        return item_popularity.get(item_id, 0) / total_popularity\n",
    "\n",
    "    user_diversities = []\n",
    "    user_novelties = []\n",
    "    \n",
    "    # We'll need the set of *all item indices* in the internal mapping\n",
    "    all_items_set = set(range(Q.shape[1]))\n",
    "\n",
    "    for user_index in tqdm(item_by_users.keys(), desc=\"Eval (rating-space diversity)\"):\n",
    "        user_id = reverse_user_map[user_index]\n",
    "\n",
    "        # Items user already rated\n",
    "        if user_id not in train_val_matrix.index:\n",
    "            continue\n",
    "        user_seen_items = train_val_matrix.loc[user_id].dropna().index  \n",
    "        seen_item_indices = {item_map[i] for i in user_seen_items if i in item_map}\n",
    "\n",
    "        n_u = len(item_by_users[user_index])\n",
    "        if n_u == 0:\n",
    "            continue\n",
    "\n",
    "        # Build user's latent factor pPlusY\n",
    "        pPlusY = P[:, user_index] + (1 / np.sqrt(n_u)) * np.sum(Y[item_by_users[user_index]], axis=0)\n",
    "\n",
    "        # Candidate (unseen) item indices\n",
    "        candidate_items = list(all_items_set - seen_item_indices)\n",
    "        \n",
    "        # Predict scores for each candidate\n",
    "        predictions = []\n",
    "        for itm_idx in candidate_items:\n",
    "            pred_score = (\n",
    "                avg \n",
    "                + B_U[user_index] \n",
    "                + B_I[itm_idx] \n",
    "                + np.dot(pPlusY, Q[:, itm_idx])\n",
    "            )\n",
    "            # We'll store the original item ID and its predicted score\n",
    "            orig_id = reverse_item_map[itm_idx]\n",
    "            predictions.append((orig_id, pred_score))\n",
    "        \n",
    "        # Sort and take top-K\n",
    "        top_k_items = sorted(predictions, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "        # 1) Intra-List Diversity in *Rating* Space\n",
    "        #    For each item in top-k, gather its column from user_item_matrix.\n",
    "        #    Then compute pairwise cosine similarities and convert to distances.\n",
    "        if len(top_k_items) > 1:\n",
    "            item_vectors = []\n",
    "            for (orig_item_id, _) in top_k_items:\n",
    "                col_idx = item_map[orig_item_id]   # internal index\n",
    "                # For rating-space, we get the entire column from user_item_matrix\n",
    "                # If it's sparse: user_item_matrix[:, col_idx].toarray().flatten()\n",
    "                # If it's dense: user_item_matrix[:, col_idx]\n",
    "                vec = user_item_matrix[:, col_idx].toarray().flatten() \\\n",
    "                      if hasattr(user_item_matrix, \"toarray\") else user_item_matrix[:, col_idx]\n",
    "                item_vectors.append(vec)\n",
    "\n",
    "            # Filter out empty vectors\n",
    "            item_vectors = [v for v in item_vectors if np.any(v)]\n",
    "            if len(item_vectors) < 2:\n",
    "                ild = 0.0\n",
    "            else:\n",
    "                sim_matrix = cosine_similarity(item_vectors)\n",
    "                n_items_in_list = len(sim_matrix)\n",
    "                # sum of similarities excluding diagonal\n",
    "                sum_sims = np.sum(sim_matrix) - np.trace(sim_matrix)\n",
    "                # number of pairs\n",
    "                denom = n_items_in_list * (n_items_in_list - 1)\n",
    "                avg_sim = sum_sims / denom\n",
    "                ild = 1.0 - avg_sim\n",
    "        else:\n",
    "            ild = 0.0\n",
    "\n",
    "        # 2) Novelty: average -log2(popularity fraction)\n",
    "        item_novelties = []\n",
    "        for (orig_item_id, _) in top_k_items:\n",
    "            frac = popularity_fraction(orig_item_id)\n",
    "            if frac <= 0:\n",
    "                # very obscure item \n",
    "                item_novelties.append(1.0) \n",
    "            else:\n",
    "                item_novelties.append(-np.log2(frac))\n",
    "        avg_novelty = np.mean(item_novelties) if item_novelties else 0.0\n",
    "\n",
    "        user_diversities.append(ild)\n",
    "        user_novelties.append(avg_novelty)\n",
    "\n",
    "    mean_diversity = np.mean(user_diversities) if user_diversities else 0.0\n",
    "    mean_novelty   = np.mean(user_novelties)  if user_novelties  else 0.0\n",
    "\n",
    "    print(f\"\\n[Rating-Space] Diversity @ {top_k}: {mean_diversity:.4f}\")\n",
    "    print(f\"[Rating-Space] Novelty   @ {top_k}: {mean_novelty:.4f}\")\n",
    "\n",
    "    return mean_diversity, mean_novelty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = csr_matrix(train_val_matrix.fillna(0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring Diversity & Novelty...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval (rating-space diversity): 100%|██████████| 27769/27769 [05:02<00:00, 91.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Rating-Space] Diversity @ 10: 0.9998\n",
      "[Rating-Space] Novelty   @ 10: 14.3572\n",
      "Diversity (ILD) at K=10: 0.9998\n",
      "Novelty at K=10:        14.3572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Suppose you trained your final model as best_model\n",
    "# and have train_val_matrix, test_matrix from your pipeline\n",
    "\n",
    "print(\"Measuring Diversity & Novelty...\")\n",
    "\n",
    "mean_diversity, mean_novelty = evaluate_diversity_novelty(\n",
    "    model=best_model, \n",
    "    train_val_matrix=train_val_matrix,\n",
    "    user_item_matrix=user_item_matrix,  # pass the sparse or dense matrix here\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "print(f\"Diversity (ILD) at K=10: {mean_diversity:.4f}\")\n",
    "print(f\"Novelty at K=10:        {mean_novelty:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion on the Observed Diversity & Novelty\n",
    "\n",
    "- **Diversity (ILD) ~ 0.9998**  \n",
    "  A value very close to **1.0** implies that, on average, the recommended items for each user share extremely low similarity in their rating vectors.  \n",
    "  - In other words, items are **almost orthogonal** in how users have rated them.  \n",
    "  - This high diversity indicates the system is providing a **very broad** set of recommendations to each user, with minimal overlap in user-rating patterns.\n",
    "\n",
    "- **Novelty ~ 14.3572**  \n",
    "  The novelty measure, based on \\(-\\log_2(\\text{popularity fraction})\\), is around **14.36**, which is quite large.  \n",
    "  - Interpreting this in terms of probabilities:  \n",
    "    \\[\n",
    "      -\\log_2(p) = 14.36 \n",
    "      \\quad\\Longleftrightarrow\\quad\n",
    "      p \\approx 2^{-14.36} \\approx 6.0 \\times 10^{-5}\n",
    "    \\]\n",
    "  - This means the recommended items are **very rare** in the training set—suggesting the system is heavily favoring less-popular (obscure) content.  \n",
    "\n",
    "Putting it all together, the system **highly diversifies** its top-10 recommendations and tends to suggest **very rare** items. From a user perspective, this could be beneficial for discovering hidden gems, but it may risk recommending items that are too obscure or lack sufficient engagement from other users.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mandi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
