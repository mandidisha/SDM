{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems Development for Marketing (Assignment): Content-Based Recommender System for Yelp and Netflix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths and Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_limit = 100000\n",
    "netflix_path = '/Users/mandidisha/Downloads/SDMmandi/training_data.csv'\n",
    "yelp_path = '/Users/mandidisha/Downloads/SDMmandi/Yelp/yelp_academic_dataset_review.json'\n",
    "dataset_choice = input(\"Choose the dataset to import (netflix or yelp): \").strip().lower()\n",
    "recommend_func = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants_df = pd.read_csv(\"/Users/mandidisha/Downloads/SDMmandi/Yelp/restaurants.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Measuring Diversity & Novelty\n",
    "\n",
    "### 1. `calculate_diversity(recommendations, feature_vectors)`\n",
    "\n",
    "**What It Does Internally**  \n",
    "- **Input**:  \n",
    "  1. A list of `recommendations` (item IDs).  \n",
    "  2. A corresponding matrix `feature_vectors` where each row represents an item’s features (e.g., TF-IDF, embeddings, etc.).  \n",
    "- **Steps**:  \n",
    "  1. **Compute Cosine Similarity**:  \n",
    "     `cosine_similarity(feature_vectors)` returns an \\(n \\times n\\) matrix, where each cell \\((i, j)\\) is the similarity between items \\(i\\) and \\(j\\).  \n",
    "  2. **Extract Upper Triangle**:  \n",
    "     We use `np.triu_indices(len(sims), k=1)` to collect all the unique pairwise similarities, ignoring the diagonal and duplicate pairs.  \n",
    "  3. **Translate Similarity to Diversity**:  \n",
    "     The final score is \\(1 - \\text{mean(similarities)}\\). If items are highly similar, the mean is large and the diversity is small. If items are quite different, the mean is small and the diversity is large (approaching 1.0).\n",
    "\n",
    "### 2. `calculate_novelty(recommendations, popularity_dict)`\n",
    "\n",
    "**What It Does Internally**  \n",
    "- **Input**:  \n",
    "  1. A list of recommended `item_id`s.  \n",
    "  2. A `popularity_dict` mapping each item to its frequency in the dataset.  \n",
    "- **Steps**:  \n",
    "  1. **Sum Over All Items**:  \n",
    "     `total_items = sum(popularity_dict.values())` gives the total interaction count in your dataset.  \n",
    "  2. **Compute Probability**:  \n",
    "     For each recommended item, we do  \n",
    "     \\[\n",
    "       \\text{prob} = \\frac{\\text{freq}(item)}{\\text{total\\_items}}\n",
    "     \\]  \n",
    "     If the item doesn’t exist in `popularity_dict`, we default to 1 (rare item).  \n",
    "  3. **Self-Information**:  \n",
    "     Novelty is defined as \\(-\\log_{2}(\\text{prob})\\). This is also known as the **information content**: items that appear less often have a lower probability and thus a higher novelty score.  \n",
    "  4. **Average Across Recommendations**:  \n",
    "     We aggregate these item-level novelty scores by taking the mean.\n",
    "\n",
    "### Why It Matters\n",
    "- **Diversity** shows whether you’re recommending a range of distinct items or just slight variations of the same thing.  \n",
    "- **Novelty** tells you if your recommendations are relatively unknown (potential for discovery) or the most common/popular choices (familiar but less exciting).\n",
    "\n",
    "Putting it all together, these metrics provide insight into how “fresh” and “varied” your recommendation lists are, complementing more traditional accuracy-oriented measures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_diversity(recommendations, feature_vectors):\n",
    "    if len(recommendations) <= 1:\n",
    "        return 0.0\n",
    "    sims = cosine_similarity(feature_vectors)\n",
    "    upper_triangle = sims[np.triu_indices(len(sims), k=1)]\n",
    "    return 1 - np.mean(upper_triangle)\n",
    "\n",
    "def calculate_novelty(recommendations, popularity_dict):\n",
    "    novelty_scores = []\n",
    "    total_items = sum(popularity_dict.values())\n",
    "    if total_items == 0:\n",
    "        return 0.0\n",
    "    for item_id in recommendations:\n",
    "        freq = popularity_dict.get(item_id, 1)\n",
    "        prob = freq / total_items\n",
    "        prob = max(prob, 1e-10) \n",
    "        novelty = -np.log2(prob)\n",
    "        novelty_scores.append(novelty)\n",
    "    return np.mean(novelty_scores) if novelty_scores else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommendation System: Netflix vs Yelp\n",
    "\n",
    "This section implements a content-based recommendation system for two datasets using different strategies tailored to their structures:\n",
    "\n",
    "---\n",
    "\n",
    "### Netflix Movie Recommendations\n",
    "\n",
    "**Goal**: Recommend movies similar to a given title based on metadata and user engagement statistics.\n",
    "\n",
    "#### **Pipeline**:\n",
    "1. **Load & Clean Data**:\n",
    "   - Read a limited number of rows (`row_limit`) from the Netflix dataset.\n",
    "   - Standardize column names and group by `movietitle` and `yearofrelease`.\n",
    "\n",
    "2. **Feature Aggregation**:\n",
    "   - Compute the average values of key content features:\n",
    "     - `user_average_rating`\n",
    "     - `scaled_movie_age`\n",
    "     - `average_rating_per_movie`\n",
    "     - `number_of_ratings_per_movie`\n",
    "   - Compute average movie ratings (`avg_rating`) and merge.\n",
    "\n",
    "3. **Feature Normalization**:\n",
    "   - Normalize content features using `MinMaxScaler`.\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "   - Create a string-based representation of each movie combining its metadata and numerical features.\n",
    "\n",
    "5. **TF-IDF & Similarity Matrix**:\n",
    "   - Use `TfidfVectorizer` to encode movie feature strings.\n",
    "   - Compute cosine similarity across all movies using `linear_kernel`.\n",
    "\n",
    "6. **Recommendation Function**:\n",
    "   - For a given `movie_title`, return the top-N most similar movies based on cosine similarity.\n",
    "\n",
    "---\n",
    "\n",
    "### Yelp Business Recommendations\n",
    "\n",
    "**Goal**: Recommend similar businesses based on average user feedback features.\n",
    "\n",
    "#### **Pipeline**:\n",
    "1. **Load & Parse JSON Data**:\n",
    "   - Read `row_limit` entries from Yelp’s line-delimited JSON format.\n",
    "\n",
    "2. **Preprocessing**:\n",
    "   - Keep only entries with valid `business_id`.\n",
    "   - Focus on numeric columns: `stars`, `useful`, `funny`, `cool`.\n",
    "   - Fill missing values with 0.\n",
    "\n",
    "3. **Feature Aggregation**:\n",
    "   - Aggregate ratings and interaction metrics per business.\n",
    "\n",
    "4. **Feature Scaling & Model Fitting**:\n",
    "   - Scale features using `StandardScaler`.\n",
    "   - Fit a `NearestNeighbors` model using **cosine similarity**.\n",
    "\n",
    "5. **Recommendation Function**:\n",
    "   - For a given `index`, retrieve the top-N most similar businesses.\n",
    "\n",
    "---\n",
    "\n",
    "### Dynamic Execution Logic\n",
    "\n",
    "A `dataset_choice` toggle allows switching between:\n",
    "- `recommend_netflix(movie_title)`\n",
    "- `recommend_yelp(index)`\n",
    "\n",
    "The active recommendation function is assigned to `recommend_func` based on the dataset selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if dataset_choice == \"netflix\":\n",
    "    # 1) Load the Netflix CSV\n",
    "    df = pd.read_csv(netflix_path, nrows=row_limit)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    \n",
    "    # 2) Group columns and define content features\n",
    "    group_cols = ['movietitle', 'yearofrelease']\n",
    "    content_cols = ['user_average_rating', 'scaled_movie_age',\n",
    "                    'average_rating_per_movie', 'number_of_ratings_per_movie']\n",
    "    \n",
    "    # 3) Aggregate by (movietitle, yearofrelease) for these features\n",
    "    df_grouped = df.groupby(group_cols)[content_cols].mean().reset_index()\n",
    "    \n",
    "    # 4) Also compute average rating across all interactions\n",
    "    avg_ratings = df.groupby(group_cols)['rating'].mean().reset_index(name='avg_rating')\n",
    "    df_grouped = pd.merge(df_grouped, avg_ratings, on=group_cols, how='left')\n",
    "    \n",
    "    # 5) Scale the numeric content columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df_grouped[content_cols] = scaler.fit_transform(df_grouped[content_cols])\n",
    "    \n",
    "    # 6) Create a combined 'moviefeatures' string for TF-IDF\n",
    "    df_grouped['moviefeatures'] = (\n",
    "        df_grouped['movietitle'].astype(str) + ' ' +\n",
    "        df_grouped['yearofrelease'].astype(str) + ' ' +\n",
    "        df_grouped['user_average_rating'].astype(str) + ' ' +\n",
    "        df_grouped['scaled_movie_age'].astype(str) + ' ' +\n",
    "        df_grouped['average_rating_per_movie'].astype(str) + ' ' +\n",
    "        df_grouped['number_of_ratings_per_movie'].astype(str)\n",
    "    )\n",
    "    \n",
    "    # 7) Compute TF-IDF matrix\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(df_grouped['moviefeatures'])\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # 8) Define the recommend function for Netflix\n",
    "    def recommend_netflix(movie_title, top_n=5):\n",
    "        matches = df_grouped[df_grouped['movietitle'] == movie_title]\n",
    "        if matches.empty:\n",
    "            print(f\" Movie not found: {movie_title}\")\n",
    "            return pd.DataFrame()\n",
    "        idx = matches.index[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        # Sort by similarity, exclude the movie itself [1:]\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "        indices = [i[0] for i in sim_scores]\n",
    "        return df_grouped.iloc[indices][['movietitle', 'yearofrelease', 'avg_rating']]\n",
    "    \n",
    "    # 9) Assign the recommend function\n",
    "    recommend_func = recommend_netflix\n",
    "\n",
    "elif dataset_choice == \"yelp\":\n",
    "    # 1) Read a subset of the Yelp JSON lines\n",
    "    lines = []\n",
    "    with open(yelp_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= row_limit:\n",
    "                break\n",
    "            lines.append(json.loads(line))\n",
    "    df = pd.DataFrame(lines)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    \n",
    "    # 2) Filter out rows with missing business_id\n",
    "    df = df[df['business_id'].notna()]\n",
    "\n",
    "    # 3) Prepare numeric columns\n",
    "    numeric_cols = ['stars', 'useful', 'funny', 'cool']\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "    \n",
    "    # 4) Aggregate these columns by business_id\n",
    "    business_profiles = df.groupby('business_id')[numeric_cols].mean().reset_index()\n",
    "    \n",
    "    # 5) Merge with restaurants_df to get the 'name' column\n",
    "    #    (Assuming you already have 'restaurants_df' loaded with at least 'business_id' and 'name')\n",
    "    business_profiles = business_profiles.merge(\n",
    "        restaurants_df[['business_id', 'name']], \n",
    "        on='business_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 6) Scale features\n",
    "    features_scaled = StandardScaler().fit_transform(business_profiles[numeric_cols])\n",
    "    \n",
    "    # 7) Fit a NearestNeighbors model\n",
    "    nn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=6)\n",
    "    nn_model.fit(features_scaled)\n",
    "    \n",
    "    # 8) Define the recommend function for Yelp\n",
    "    def recommend_yelp(index, top_n=5):\n",
    "        if index >= len(business_profiles):\n",
    "            print(\"Invalid business index\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Get top_n+1 neighbors to skip the item itself\n",
    "        distances, indices = nn_model.kneighbors([features_scaled[index]], n_neighbors=top_n+1)\n",
    "        \n",
    "        # Slice out the recommended neighbors, skipping the first one\n",
    "        recommended = business_profiles.iloc[indices[0][1:]].copy()\n",
    "        \n",
    "        # Return columns that include the name, plus numeric info\n",
    "        return recommended[['business_id', 'name', 'stars', 'useful', 'funny', 'cool']]\n",
    "    \n",
    "    # 9) Assign the recommend function\n",
    "    recommend_func = recommend_yelp\n",
    "\n",
    "else:\n",
    "    # Optional fallback if user input is invalid\n",
    "    print(\"Invalid choice. Please enter 'netflix' or 'yelp'. recommend_func is not set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Top-N Recommendations\n",
    "\n",
    "This function evaluates the quality of **Top-N content-based recommendations** using classification-style metrics. It supports both the **Netflix** and **Yelp** datasets, adjusting logic based on `dataset_choice`.\n",
    "\n",
    "---\n",
    "\n",
    "### Function: `evaluate_recommendations(df_source, recommend_func, top_n=5, rating_threshold=4.0, sample_size=100)`\n",
    "\n",
    "#### **Inputs**:\n",
    "- `df_source`: DataFrame containing the source items (e.g., movies or businesses)\n",
    "- `recommend_func`: Function that returns recommendations for a given item or index\n",
    "- `top_n`: Number of recommendations to generate per item (default: 5)\n",
    "- `rating_threshold`: Minimum rating considered \"positive\" (default: 4.0)\n",
    "- `sample_size`: Number of samples to evaluate (default: 100)\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluation Logic**\n",
    "\n",
    "For each item in the sample:\n",
    "1. **Netflix**:\n",
    "   - Retrieve the `avg_rating` of the selected movie as the **true label** (positive if ≥ threshold).\n",
    "   - Generate `top_n` recommendations using `recommend_func`.\n",
    "   - Compare each recommendation’s average rating to the threshold.\n",
    "\n",
    "2. **Yelp**:\n",
    "   - Use `stars` of the selected business as the true label.\n",
    "   - Generate recommendations using nearest neighbors.\n",
    "   - Compare predicted businesses' `stars` to the threshold.\n",
    "\n",
    "---\n",
    "\n",
    "### **Metrics Computed**\n",
    "\n",
    "- **Precision**: Fraction of recommended items that are relevant  \n",
    "  \\( \\text{Precision} = \\frac{TP}{TP + FP} \\)\n",
    "- **Recall**: Whether at least one relevant item was recommended  \n",
    "  \\( \\text{Recall} = 1 \\) if at least one TP and true label is positive, else 0\n",
    "- **Accuracy**: Proportion of predictions matching the true label\n",
    "- **F1 Score**: Harmonic mean of precision and recall\n",
    "\n",
    "---\n",
    "\n",
    "### **Output**\n",
    "\n",
    "Prints the average values of all metrics across valid samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(df_source, recommend_func, top_n=5, rating_threshold=4.0, sample_size=100):\n",
    "    precisions, recalls, accuracies = [], [], []\n",
    "    diversity_scores, novelty_scores = [], []\n",
    "\n",
    "    # --- Popularity setup\n",
    "    if dataset_choice == \"netflix\":\n",
    "        popularity_dict = df['movietitle'].value_counts().to_dict()\n",
    "    elif dataset_choice == \"yelp\":\n",
    "        popularity_dict = df['business_id'].value_counts().to_dict()\n",
    "\n",
    "    for i in range(min(sample_size, len(df_source))):\n",
    "        try:\n",
    "            # --- Get recommendation and labels\n",
    "            if dataset_choice == \"netflix\":\n",
    "                true_label = df_source.iloc[i]['avg_rating'] >= rating_threshold\n",
    "                movie_title = df_source.iloc[i]['movietitle']\n",
    "                recs = recommend_func(movie_title, top_n=top_n)\n",
    "                if recs.empty or 'avg_rating' not in recs.columns:\n",
    "                    continue\n",
    "                pred_labels = recs['avg_rating'] >= rating_threshold\n",
    "\n",
    "                # --- Diversity\n",
    "                rec_indices = recs.index\n",
    "                diversity = calculate_diversity(recs, tfidf_matrix[rec_indices])\n",
    "                # --- Novelty\n",
    "                novelty = calculate_novelty(recs['movietitle'], popularity_dict)\n",
    "\n",
    "            elif dataset_choice == \"yelp\":\n",
    "                true_label = df.iloc[i]['stars'] >= rating_threshold\n",
    "                recs = recommend_func(i, top_n=top_n)\n",
    "                if recs.empty or 'stars' not in recs.columns:\n",
    "                    continue\n",
    "                pred_labels = recs['stars'] >= rating_threshold\n",
    "\n",
    "                # --- Diversity\n",
    "                rec_indices = recs.index\n",
    "                rec_feature_vectors = features_scaled[rec_indices]\n",
    "                diversity = calculate_diversity(recs, rec_feature_vectors)\n",
    "                # --- Novelty\n",
    "                novelty = calculate_novelty(recs['business_id'], popularity_dict)\n",
    "\n",
    "            # --- Evaluation metrics\n",
    "            tp = pred_labels.sum() if true_label else 0\n",
    "            precision = tp / len(pred_labels) if len(pred_labels) > 0 else 0\n",
    "            recall = 1 if tp > 0 and true_label else 0\n",
    "            accuracy = sum(pred_labels == true_label) / len(pred_labels)\n",
    "\n",
    "            # --- Append scores\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            accuracies.append(accuracy)\n",
    "            diversity_scores.append(diversity)\n",
    "            novelty_scores.append(novelty)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipped index {i} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not precisions:\n",
    "        print(\"⚠️ No valid evaluations. Check dataset or prediction output.\")\n",
    "        return\n",
    "\n",
    "    # --- Aggregate\n",
    "    avg_precision = np.mean(precisions)\n",
    "    avg_recall = np.mean(recalls)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_diversity = np.mean(diversity_scores)\n",
    "    avg_novelty = np.mean(novelty_scores)\n",
    "    f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall + 1e-6)\n",
    "\n",
    "    # --- Print Results\n",
    "    print(f\"\\n🔍 Evaluation Metrics (Top {top_n} Recommendations):\")\n",
    "    print(f\"Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Recall:    {avg_recall:.4f}\")\n",
    "    print(f\"Accuracy:  {avg_accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Diversity: {avg_diversity:.4f}\")\n",
    "    print(f\"Novelty:   {avg_novelty:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Sample Recommendations and Evaluation\n",
    "\n",
    "This section runs a **live recommendation** and evaluates system performance using classification metrics based on a threshold (e.g., 3.0-star or rating cutoff).\n",
    "\n",
    "---\n",
    "\n",
    "### Logic:\n",
    "\n",
    "#### **If `dataset_choice == \"netflix\"`**\n",
    "- Picks a random movie title from the grouped dataset.\n",
    "- Prints Top-5 recommended movies using the `recommend_func`.\n",
    "- Evaluates recommendation quality across 100 samples using:\n",
    "  - `avg_rating` ≥ 3.0 as a positive label\n",
    "  - Precision, Recall, Accuracy, and F1 Score are computed\n",
    "\n",
    "#### **If `dataset_choice == \"yelp\"`**\n",
    "- Selects the business at index `0` and prints Top-5 similar businesses.\n",
    "- Runs evaluation over 100 randomly sampled businesses using:\n",
    "  - `stars` ≥ 3.0 as the positive label\n",
    "  - Same evaluation metrics as in Netflix\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of the business names have nan values in restaurant.csv so thats why we keep business id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Recommendations for '7 Seconds':\n",
      "              movietitle  yearofrelease  avg_rating\n",
      "1                  8 Man           1992    2.129032\n",
      "2                Boycott           2001    3.598470\n",
      "3  By Dawn's Early Light           2000    3.324675\n",
      "4              Character           1997    3.641153\n",
      "5           Chump Change           2000    2.246305\n",
      "\n",
      "🔍 Evaluation Metrics (Top 10 Recommendations):\n",
      "Precision: 0.4467\n",
      "Recall:    0.7667\n",
      "Accuracy:  0.5267\n",
      "F1 Score:  0.5645\n",
      "Diversity: 0.9932\n",
      "Novelty:   7.5733\n"
     ]
    }
   ],
   "source": [
    "if dataset_choice == \"netflix\":\n",
    "    sample_title = df_grouped.iloc[0]['movietitle']\n",
    "    print(f\"\\n🎬 Recommendations for '{sample_title}':\")\n",
    "    print(recommend_func(sample_title))\n",
    "    evaluate_recommendations(df_grouped, recommend_func, top_n=10, rating_threshold=3.0, sample_size=100)\n",
    "\n",
    "elif dataset_choice == \"yelp\":\n",
    "    print(f\"\\n🏪 Recommendations for business at index :\")\n",
    "    print(recommend_func(0))\n",
    "    evaluate_recommendations(df, recommend_func, top_n=10, rating_threshold=3.0, sample_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Netflix vs Yelp Content-Based Recommendation Performance\n",
    "\n",
    "This section compares the performance of content-based recommenders across two datasets — Netflix (movies) and Yelp (businesses) — based on Top-5 recommendations.\n",
    "\n",
    "---\n",
    "\n",
    "### Netflix Recommendations\n",
    "**Example Input:** '7 Seconds'  \n",
    "**Top-5 Recommendations:**\n",
    "- 8 Man (1992)\n",
    "- Boycott (2001)\n",
    "- By Dawn's Early Light (2000)\n",
    "- Character (1997)\n",
    "- Chump Change (2000)\n",
    "\n",
    "**Evaluation Metrics (Top 5):**\n",
    "\n",
    "| Metric     | Value   |\n",
    "|------------|---------|\n",
    "| Precision  | 0.4467  |\n",
    "| Recall     | 0.7667  |\n",
    "| Accuracy   | 0.5267  |\n",
    "| F1 Score   | 0.5645  |\n",
    "| Diversity  | 0.9932  |\n",
    "| Novelty    | 7.5733  |\n",
    "\n",
    "---\n",
    "\n",
    "### Yelp Recommendations\n",
    "**Example Input:** Business at index 0  \n",
    "**Top-5 Recommendations:**\n",
    "- 8hgo446H2HoYlZocEi1SJw – 4.25 stars  \n",
    "- OkSjPjMwXQ77h7kzhhyhDg – 4.60 stars  \n",
    "- K45LUT-_MRhHJOzy5nBBjQ – 5.00 stars  \n",
    "- 6p07zfmJWvytr0paqpyvbg – 4.35 stars  \n",
    "- J6MGQigHItdSlG-3XZ1myA – 4.13 stars\n",
    "\n",
    "**Evaluation Metrics (Top 5):**\n",
    "\n",
    "| Metric     | Value   |\n",
    "|------------|---------|\n",
    "| Precision  | 0.7400  |\n",
    "| Recall     | 0.7900  |\n",
    "| Accuracy   | 0.7500  |\n",
    "| F1 Score   | 0.7605  |\n",
    "| Diversity  | 0.0091  |\n",
    "| Novelty    | 14.5776 |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Comparison\n",
    "\n",
    "| Metric     | Netflix     | Yelp        | Observation |\n",
    "|------------|-------------|-------------|-------------|\n",
    "| Precision  | 0.4467       | **0.7400**  | Yelp performs better at recommending relevant items |\n",
    "| Recall     | 0.7667      | 0.7900      | Both systems recall relevant items well |\n",
    "| Accuracy   | 0.5267      | **0.7500**  | Yelp provides more consistent classification |\n",
    "| F1 Score   | 0.5645     | **0.7605**  | Yelp has better overall classification balance |\n",
    "| Diversity  | **0.9932**  | 0.0091      | Netflix offers highly diverse recommendations |\n",
    "| Novelty    | 7.5733      | **14.5776** | Yelp suggests much rarer items on average |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- Netflix offers high diversity and moderate novelty but lower precision and overall classification accuracy.\n",
    "- Yelp shows strong accuracy and recall but very low diversity, likely due to homogeneity in business features.\n",
    "- The contrast illustrates a tradeoff between recommendation **relevance** and **diversity**, depending on the dataset and features used.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7397 out of 9973 have NaN for name.\n"
     ]
    }
   ],
   "source": [
    "# Number of NaN names:\n",
    "num_nan_names = business_profiles['name'].isna().sum()\n",
    "total_rows = len(business_profiles)\n",
    "print(f\"{num_nan_names} out of {total_rows} have NaN for name.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
